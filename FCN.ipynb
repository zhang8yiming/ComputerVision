{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhang8yiming/ComputerVision/blob/main/FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rujHwDzXSvgy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i859Ix_Svgz"
      },
      "source": [
        "### 建立block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "elUwxzikSvgz"
      },
      "outputs": [],
      "source": [
        "# Block 包含：conv-bn-relu\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, padding=1, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.bn1(self.conv1(x)))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuO99kwQSvgz"
      },
      "source": [
        "### 建立layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7m4358MLSvgz"
      },
      "outputs": [],
      "source": [
        "# 建立 layer 加入很多 Block\n",
        "def make_layers(in_channels, layer_list):\n",
        "    layers = []\n",
        "    for out_channels in layer_list:\n",
        "      layers += [Block(in_channels, out_channels)]\n",
        "      in_channels = out_channels\n",
        "    return nn.Sequential(*layers)\n",
        "            \n",
        "\n",
        "class Layer(nn.Module):\n",
        "    def __init__(self, in_channels, layer_list):\n",
        "        super(Layer, self).__init__()\n",
        "        self.layer = make_layers(in_channels, layer_list)\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afHTOdJbSvgz"
      },
      "source": [
        "### 建立VGG-19BN模型\n",
        "\n",
        "* 'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "* 'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "* 'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "* 'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FCN-32s"
      ],
      "metadata": {
        "id": "tDhgwFSDO3Uf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DDWvBug2Svgz"
      },
      "outputs": [],
      "source": [
        "class VGG_fcn32s(nn.Module):\n",
        "    '''\n",
        "    将 VGG model 改变成 FCN-32s \n",
        "    '''\n",
        "    def __init__(self, n_class=21):\n",
        "        super(VGG_fcn32s, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=100) # padding = 100，传统 VGG 为1\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.layer1 = Layer(64, [64]) # 第一组 Stage\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 降采样 /2\n",
        "        self.layer2 = Layer(64, [128, 128]) # 第二组 Stage\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)# 降采样 /4\n",
        "        self.layer3 = Layer(128, [256, 256, 256, 256]) # 第三组 Stage\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)# 降采样 /8\n",
        "        self.layer4 = Layer(256, [512, 512, 512, 512]) # 第四组 Stage\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)# 降采样 /16\n",
        "        self.layer5 = Layer(512, [512, 512, 512, 512]) # 第五组 Stage\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)# 降采样 /32\n",
        "\n",
        "        # modify to be compatible with segmentation and classification\n",
        "        #self.fc6 = nn.Linear(512*7*7, 4096) # 全连接层 VGG\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7) # padding = 0\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout()\n",
        "\n",
        "        #self.fc7 = nn.Linear(4096, 4096) # 全连接层 VGG\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout()\n",
        "\n",
        "        #self.score = nn.Linear(4096, n_class) # 全连接层 VGG\n",
        "        self.score = nn.Conv2d(4096, n_class, 1)\n",
        "        \n",
        "        self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, 32) # 上采样 32 倍\n",
        "\n",
        "    def forward(self, x):\n",
        "        f0 = self.relu1(self.bn1(self.conv1(x)))\n",
        "        f1 = self.pool1(self.layer1(f0))\n",
        "        f2 = self.pool2(self.layer2(f1))\n",
        "        f3 = self.pool3(self.layer3(f2))\n",
        "        f4 = self.pool4(self.layer4(f3))\n",
        "        f5 = self.pool5(self.layer5(f4))\n",
        "        #f5 = f5.view(f5.size(0), -1) \n",
        "        print('f5.shape:', f5.shape)\n",
        "        f6 = self.drop6(self.relu6(self.fc6(f5)))\n",
        "        print('f6.shape:', f6.shape)\n",
        "        f7 = self.drop7(self.relu7(self.fc7(f6)))\n",
        "        print('f7.shape:', f7.shape)\n",
        "        score = self.score(f7)\n",
        "        upscore = self.upscore(score)\n",
        "        # crop 19 再相加融合\n",
        "        upscore = upscore[:, :, 19:19+x.size(2), 19:19+x.size(3)].contiguous()\n",
        "        return upscore\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = VGG_fcn32s()\n",
        "x = torch.randn((2, 3, 227, 227), dtype=torch.float32)\n",
        "y = vgg_model(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4S0PmWaoQ9n",
        "outputId": "ac4f372d-56cc-485c-af4b-5b844d3bb0a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f5.shape: torch.Size([2, 512, 13, 13])\n",
            "f6.shape: torch.Size([2, 4096, 7, 7])\n",
            "f7.shape: torch.Size([2, 4096, 7, 7])\n",
            "torch.Size([2, 21, 227, 227])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYImvnMqSvgz"
      },
      "source": [
        "### 上采样模块的权重初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rahcdQWSvgz"
      },
      "outputs": [],
      "source": [
        "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
        "    factor = (kernel_size + 1) // 2\n",
        "    \n",
        "    center = kernel_size / 2 - 0.5\n",
        "    og = np.ogrid[:kernel_size, :kernel_size]\n",
        "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
        "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype='float32')\n",
        "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
        "    return torch.from_numpy(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mAhHPeppSvgz",
        "outputId": "fb744c5d-f1f3-4b88-d1bd-17d241d286db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[0.0625, 0.1875, 0.1875, 0.0625],\n",
            "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
            "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
            "          [0.0625, 0.1875, 0.1875, 0.0625]]],\n",
            "\n",
            "\n",
            "        [[[0.0625, 0.1875, 0.1875, 0.0625],\n",
            "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
            "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
            "          [0.0625, 0.1875, 0.1875, 0.0625]]],\n",
            "\n",
            "\n",
            "        [[[0.0625, 0.1875, 0.1875, 0.0625],\n",
            "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
            "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
            "          [0.0625, 0.1875, 0.1875, 0.0625]]]], requires_grad=True)\n",
            "(333, 385, 3)\n",
            "(666, 770, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "x = cv2.imread('cat.png')\n",
        "x_torch = torch.from_numpy(x.astype(np.float32)).permute(2, 0, 1).unsqueeze(0)\n",
        "# channels, bias ?\n",
        "conv_trans = nn.ConvTranspose2d(3, 3, 4, 2, 1, groups=3, bias=False)\n",
        "conv_trans.weight.data = bilinear_kernel(3, 1, 4)\n",
        "print(conv_trans.weight)\n",
        "y_torch = conv_trans(x_torch)\n",
        "y = y_torch.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "x = x.astype(np.uint8)\n",
        "print(x.shape)\n",
        "cv2.imshow('show', x)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "y = y.astype(np.uint8)\n",
        "print(y.shape)\n",
        "cv2.imshow('show', y)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FCN-8s"
      ],
      "metadata": {
        "id": "Ie9dfc4OTTkC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTs1MYKrSvg2"
      },
      "source": [
        "### 建立VGG_19bn_8s模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn_p1ubkSvg2"
      },
      "outputs": [],
      "source": [
        "class VGG_19bn_8s(nn.Module):\n",
        "    def __init__(self, n_class=21):\n",
        "        super(VGG_19bn_8s, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=100)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.layer1 = Layer(64, [64])\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer2 = Layer(64, [128, 128])\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer3 = Layer(128, [256, 256, 256, 256])\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer4 = Layer(256, [512, 512, 512, 512])\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.layer5 = Layer(512, [512, 512, 512, 512])\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7) # padding=0\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
        "        self.trans_f4 = nn.Conv2d(512, n_class, 1) # 通道数归一化成 n_calss\n",
        "        self.trans_f3 = nn.Conv2d(256, n_class, 1) # 通道数归一化成 n_calss\n",
        "\n",
        "        self.up2times = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False) # 上采样2倍\n",
        "        self.up4times = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False) # 上采样2倍\n",
        "        self.up32times = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 16, stride=8, bias=False) # 上采样8倍\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                m.weight.data = bilinear_kernel(n_class, n_class, m.kernel_size[0])\n",
        "    \n",
        "    def forward(self, x):\n",
        "        f0 = self.relu1(self.bn1(self.conv1(x)))\n",
        "        f1 = self.pool1(self.layer1(f0))\n",
        "        f2 = self.pool2(self.layer2(f1))\n",
        "        f3 = self.pool3(self.layer3(f2))\n",
        "        f4 = self.pool4(self.layer4(f3))\n",
        "        f5 = self.pool5(self.layer5(f4))\n",
        "        \n",
        "        f6 = self.drop6(self.relu6(self.fc6(f5)))\n",
        "        f7 = self.score_fr(self.drop7(self.relu7(self.fc7(f6))))\n",
        "        \n",
        "        up2_feat = self.up2times(f7) # 上采样2倍\n",
        "        h = self.trans_f4(f4) # pool4 通道数归一化成 n_calss，便于相加\n",
        "        print(h.shape)\n",
        "        print(up2_feat.shape)\n",
        "        h = h[:, :, 5:5 + up2_feat.size(2), 5:5 + up2_feat.size(3)] \n",
        "        h = h + up2_feat\n",
        "        \n",
        "        up4_feat = self.up4times(h) # 上采样2倍\n",
        "        h = self.trans_f3(f3) # pool3 通道数归一化成 n_calss，便于相加\n",
        "        print(h.shape)\n",
        "        print(up4_feat.shape)\n",
        "        h = h[:, :, 9:9 + up4_feat.size(2), 9:9 + up4_feat.size(3)]\n",
        "        h = h + up4_feat\n",
        "        \n",
        "        h = self.up32times(h) # 上采样8倍\n",
        "        print(h.shape)\n",
        "        final_scores = h[:, :, 31:31 + x.size(2), 31:31 + x.size(3)].contiguous()\n",
        "        \n",
        "        return final_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y_dDgwzSvg3",
        "outputId": "509e5433-1ef9-42ba-971e-5f86b4335586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 21, 16, 16])\n",
            "torch.Size([2, 21, 6, 6])\n",
            "torch.Size([2, 21, 32, 32])\n",
            "torch.Size([2, 21, 14, 14])\n",
            "torch.Size([2, 21, 120, 120])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 21, 58, 58])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = VGG_19bn_8s(21)\n",
        "x = torch.randn(2, 3, 58, 58)\n",
        "model.eval()\n",
        "y_vgg = model(x)\n",
        "y_vgg.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tev8evfSvg3",
        "outputId": "adcf69b8-11fb-40e8-b39c-e85fe24f14b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 21, 26, 26])\n",
            "torch.Size([2, 21, 16, 16])\n",
            "torch.Size([2, 21, 52, 52])\n",
            "torch.Size([2, 21, 34, 34])\n",
            "torch.Size([2, 21, 280, 280])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 422, 422]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 422, 422]             128\n",
            "              ReLU-3         [-1, 64, 422, 422]               0\n",
            "            Conv2d-4         [-1, 64, 422, 422]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 422, 422]             128\n",
            "              ReLU-6         [-1, 64, 422, 422]               0\n",
            "             Block-7         [-1, 64, 422, 422]               0\n",
            "             Layer-8         [-1, 64, 422, 422]               0\n",
            "         MaxPool2d-9         [-1, 64, 211, 211]               0\n",
            "           Conv2d-10        [-1, 128, 211, 211]          73,856\n",
            "      BatchNorm2d-11        [-1, 128, 211, 211]             256\n",
            "             ReLU-12        [-1, 128, 211, 211]               0\n",
            "            Block-13        [-1, 128, 211, 211]               0\n",
            "           Conv2d-14        [-1, 128, 211, 211]         147,584\n",
            "      BatchNorm2d-15        [-1, 128, 211, 211]             256\n",
            "             ReLU-16        [-1, 128, 211, 211]               0\n",
            "            Block-17        [-1, 128, 211, 211]               0\n",
            "            Layer-18        [-1, 128, 211, 211]               0\n",
            "        MaxPool2d-19        [-1, 128, 105, 105]               0\n",
            "           Conv2d-20        [-1, 256, 105, 105]         295,168\n",
            "      BatchNorm2d-21        [-1, 256, 105, 105]             512\n",
            "             ReLU-22        [-1, 256, 105, 105]               0\n",
            "            Block-23        [-1, 256, 105, 105]               0\n",
            "           Conv2d-24        [-1, 256, 105, 105]         590,080\n",
            "      BatchNorm2d-25        [-1, 256, 105, 105]             512\n",
            "             ReLU-26        [-1, 256, 105, 105]               0\n",
            "            Block-27        [-1, 256, 105, 105]               0\n",
            "           Conv2d-28        [-1, 256, 105, 105]         590,080\n",
            "      BatchNorm2d-29        [-1, 256, 105, 105]             512\n",
            "             ReLU-30        [-1, 256, 105, 105]               0\n",
            "            Block-31        [-1, 256, 105, 105]               0\n",
            "           Conv2d-32        [-1, 256, 105, 105]         590,080\n",
            "      BatchNorm2d-33        [-1, 256, 105, 105]             512\n",
            "             ReLU-34        [-1, 256, 105, 105]               0\n",
            "            Block-35        [-1, 256, 105, 105]               0\n",
            "            Layer-36        [-1, 256, 105, 105]               0\n",
            "        MaxPool2d-37          [-1, 256, 52, 52]               0\n",
            "           Conv2d-38          [-1, 512, 52, 52]       1,180,160\n",
            "      BatchNorm2d-39          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-40          [-1, 512, 52, 52]               0\n",
            "            Block-41          [-1, 512, 52, 52]               0\n",
            "           Conv2d-42          [-1, 512, 52, 52]       2,359,808\n",
            "      BatchNorm2d-43          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-44          [-1, 512, 52, 52]               0\n",
            "            Block-45          [-1, 512, 52, 52]               0\n",
            "           Conv2d-46          [-1, 512, 52, 52]       2,359,808\n",
            "      BatchNorm2d-47          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-48          [-1, 512, 52, 52]               0\n",
            "            Block-49          [-1, 512, 52, 52]               0\n",
            "           Conv2d-50          [-1, 512, 52, 52]       2,359,808\n",
            "      BatchNorm2d-51          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-52          [-1, 512, 52, 52]               0\n",
            "            Block-53          [-1, 512, 52, 52]               0\n",
            "            Layer-54          [-1, 512, 52, 52]               0\n",
            "        MaxPool2d-55          [-1, 512, 26, 26]               0\n",
            "           Conv2d-56          [-1, 512, 26, 26]       2,359,808\n",
            "      BatchNorm2d-57          [-1, 512, 26, 26]           1,024\n",
            "             ReLU-58          [-1, 512, 26, 26]               0\n",
            "            Block-59          [-1, 512, 26, 26]               0\n",
            "           Conv2d-60          [-1, 512, 26, 26]       2,359,808\n",
            "      BatchNorm2d-61          [-1, 512, 26, 26]           1,024\n",
            "             ReLU-62          [-1, 512, 26, 26]               0\n",
            "            Block-63          [-1, 512, 26, 26]               0\n",
            "           Conv2d-64          [-1, 512, 26, 26]       2,359,808\n",
            "      BatchNorm2d-65          [-1, 512, 26, 26]           1,024\n",
            "             ReLU-66          [-1, 512, 26, 26]               0\n",
            "            Block-67          [-1, 512, 26, 26]               0\n",
            "           Conv2d-68          [-1, 512, 26, 26]       2,359,808\n",
            "      BatchNorm2d-69          [-1, 512, 26, 26]           1,024\n",
            "             ReLU-70          [-1, 512, 26, 26]               0\n",
            "            Block-71          [-1, 512, 26, 26]               0\n",
            "            Layer-72          [-1, 512, 26, 26]               0\n",
            "        MaxPool2d-73          [-1, 512, 13, 13]               0\n",
            "           Conv2d-74           [-1, 4096, 7, 7]     102,764,544\n",
            "             ReLU-75           [-1, 4096, 7, 7]               0\n",
            "        Dropout2d-76           [-1, 4096, 7, 7]               0\n",
            "           Conv2d-77           [-1, 4096, 7, 7]      16,781,312\n",
            "             ReLU-78           [-1, 4096, 7, 7]               0\n",
            "        Dropout2d-79           [-1, 4096, 7, 7]               0\n",
            "           Conv2d-80             [-1, 21, 7, 7]          86,037\n",
            "  ConvTranspose2d-81           [-1, 21, 16, 16]           7,056\n",
            "           Conv2d-82           [-1, 21, 26, 26]          10,773\n",
            "  ConvTranspose2d-83           [-1, 21, 34, 34]           7,056\n",
            "           Conv2d-84           [-1, 21, 52, 52]           5,397\n",
            "  ConvTranspose2d-85         [-1, 21, 280, 280]         112,896\n",
            "================================================================\n",
            "Total params: 139,810,463\n",
            "Trainable params: 139,810,463\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 1741.07\n",
            "Params size (MB): 533.33\n",
            "Estimated Total Size (MB): 2274.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXt0kDpFMvNh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}